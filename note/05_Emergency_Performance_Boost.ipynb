{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš¨ ê¸´ê¸‰ ì„±ëŠ¥ ê°œì„  íŒŒì´í”„ë¼ì¸\n",
        "\n",
        "## ëª©í‘œ: ë² ì´ìŠ¤ë¼ì¸ LSTM ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ\n",
        "- **ì „ëµ**: ë‹¨ìˆœí•˜ê³  íš¨ê³¼ì ì¸ ì ‘ê·¼\n",
        "- **ê¸°í•œ**: ì˜¤ëŠ˜ ì €ë…ê¹Œì§€\n",
        "- **í•µì‹¬**: ë§¤ì¶œìˆ˜ëŸ‰ ì¤‘ì‹¬ì˜ ê°„ê²°í•œ í”¼ì²˜ë§\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n",
            "â° ì‹œì‘ ì‹œê°„: 2025-08-24 17:11:11\n",
            "\n",
            "ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ LSTM ì„±ëŠ¥:\n",
            "   í‰ê· : 9.739\n",
            "   í‘œì¤€í¸ì°¨: 36.115\n",
            "   ìµœëŒ€ê°’: 1057.813\n",
            "   0ì´ ì•„ë‹Œ ë¹„ìœ¨: 0.874\n",
            "   ëª©í‘œ: í‰ê·  9.739 ì´ìƒ!\n"
          ]
        }
      ],
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "print(\"ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n",
        "print(f\"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ í™•ì¸\n",
        "baseline = pd.read_csv('../baseline_submission.csv')\n",
        "baseline_stats = baseline.iloc[:, 1:].values\n",
        "print(f\"\\nğŸ“Š ë² ì´ìŠ¤ë¼ì¸ LSTM ì„±ëŠ¥:\")\n",
        "print(f\"   í‰ê· : {baseline_stats.mean():.3f}\")\n",
        "print(f\"   í‘œì¤€í¸ì°¨: {baseline_stats.std():.3f}\")\n",
        "print(f\"   ìµœëŒ€ê°’: {baseline_stats.max():.3f}\")\n",
        "print(f\"   0ì´ ì•„ë‹Œ ë¹„ìœ¨: {(baseline_stats > 0).mean():.3f}\")\n",
        "print(f\"   ëª©í‘œ: í‰ê·  {baseline_stats.mean():.3f} ì´ìƒ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‚ ë°ì´í„° ë¡œë“œ...\n",
            "ğŸ“Š í›ˆë ¨ ë°ì´í„°: (102676, 6)\n",
            "ğŸ“… ê¸°ê°„: 2023-01-01 00:00:00 ~ 2024-06-15 00:00:00\n",
            "ğŸª ì—…ì¥-ë©”ë‰´ ìˆ˜: 193\n",
            "\n",
            "ğŸ“‹ ë°ì´í„° ìƒ˜í”Œ:\n",
            "        ì˜ì—…ì¼ì            ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…  ë§¤ì¶œìˆ˜ëŸ‰  dayofweek  month  is_weekend\n",
            "0 2023-01-01  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸     0          6      1        True\n",
            "1 2023-01-02  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸     0          0      1       False\n",
            "2 2023-01-03  ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ_1ì¸ ìˆ˜ì €ì„¸íŠ¸     0          1      1       False\n"
          ]
        }
      ],
      "source": [
        "# ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì „ì²˜ë¦¬\n",
        "print(\"ğŸ“‚ ë°ì´í„° ë¡œë“œ...\")\n",
        "train = pd.read_csv('../data/train/train.csv')\n",
        "\n",
        "# ìŒìˆ˜ ì²˜ë¦¬\n",
        "train['ë§¤ì¶œìˆ˜ëŸ‰'] = train['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0)\n",
        "\n",
        "# ë‚ ì§œ ë³€í™˜\n",
        "train['ì˜ì—…ì¼ì'] = pd.to_datetime(train['ì˜ì—…ì¼ì'])\n",
        "\n",
        "# ê°„ë‹¨í•œ ì‹œê°„ í”¼ì²˜ë§Œ ì¶”ê°€\n",
        "train['dayofweek'] = train['ì˜ì—…ì¼ì'].dt.dayofweek\n",
        "train['month'] = train['ì˜ì—…ì¼ì'].dt.month  \n",
        "train['is_weekend'] = train['dayofweek'].isin([5, 6])\n",
        "\n",
        "print(f\"ğŸ“Š í›ˆë ¨ ë°ì´í„°: {train.shape}\")\n",
        "print(f\"ğŸ“… ê¸°ê°„: {train['ì˜ì—…ì¼ì'].min()} ~ {train['ì˜ì—…ì¼ì'].max()}\")\n",
        "print(f\"ğŸª ì—…ì¥-ë©”ë‰´ ìˆ˜: {train['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].nunique()}\")\n",
        "\n",
        "# ìƒ˜í”Œ í™•ì¸\n",
        "print(f\"\\nğŸ“‹ ë°ì´í„° ìƒ˜í”Œ:\")\n",
        "print(train.head(3)[['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ë§¤ì¶œìˆ˜ëŸ‰', 'dayofweek', 'month', 'is_weekend']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ í•µì‹¬ í”¼ì²˜ ìƒì„±...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… í•µì‹¬ í”¼ì²˜ ìƒì„± ì™„ë£Œ\n",
            "\n",
            "ğŸ” ê²°ì¸¡ì¹˜ í˜„í™©:\n",
            "   sales_lag_1: 193ê°œ (0.2%)\n",
            "   sales_lag_7: 1,351ê°œ (1.3%)\n",
            "   sales_lag_14: 2,702ê°œ (2.6%)\n",
            "   sales_ma_7: 0ê°œ (0.0%)\n",
            "   sales_ma_14: 0ê°œ (0.0%)\n",
            "   sales_max_7: 0ê°œ (0.0%)\n",
            "   sales_min_7: 0ê°œ (0.0%)\n",
            "\n",
            "âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# ğŸ’¡ í•µì‹¬ ì „ëµ: ê°„ë‹¨í•œ ë¼ê·¸ í”¼ì²˜ + íŠ¸ë Œë“œ ê¸°ë°˜ ì ‘ê·¼\n",
        "print(\"ğŸ”§ í•µì‹¬ í”¼ì²˜ ìƒì„±...\")\n",
        "\n",
        "def create_core_features(df):\n",
        "    \"\"\"ë§¤ì¶œìˆ˜ëŸ‰ ì¤‘ì‹¬ì˜ í•µì‹¬ í”¼ì²˜ë§Œ ìƒì„±\"\"\"\n",
        "    features_df = df.copy()\n",
        "    \n",
        "    # ì—…ì¥-ë©”ë‰´ë³„ë¡œ ë¼ê·¸ í”¼ì²˜ ìƒì„±\n",
        "    for venue_menu, group in df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'):\n",
        "        mask = features_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == venue_menu\n",
        "        sorted_data = group.sort_values('ì˜ì—…ì¼ì')\n",
        "        \n",
        "        # ê°„ë‹¨í•œ ë¼ê·¸ í”¼ì²˜\n",
        "        features_df.loc[mask, 'sales_lag_1'] = sorted_data['ë§¤ì¶œìˆ˜ëŸ‰'].shift(1).values\n",
        "        features_df.loc[mask, 'sales_lag_7'] = sorted_data['ë§¤ì¶œìˆ˜ëŸ‰'].shift(7).values\n",
        "        features_df.loc[mask, 'sales_lag_14'] = sorted_data['ë§¤ì¶œìˆ˜ëŸ‰'].shift(14).values\n",
        "        \n",
        "        # ì´ë™í‰ê· \n",
        "        features_df.loc[mask, 'sales_ma_7'] = sorted_data['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(7, min_periods=1).mean().values\n",
        "        features_df.loc[mask, 'sales_ma_14'] = sorted_data['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(14, min_periods=1).mean().values\n",
        "        \n",
        "        # ìµœê·¼ ìµœëŒ€/ìµœì†Œ (ê°„ë‹¨í•œ íŠ¸ë Œë“œ)\n",
        "        features_df.loc[mask, 'sales_max_7'] = sorted_data['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(7, min_periods=1).max().values\n",
        "        features_df.loc[mask, 'sales_min_7'] = sorted_data['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(7, min_periods=1).min().values\n",
        "    \n",
        "    return features_df\n",
        "\n",
        "# í”¼ì²˜ ìƒì„±\n",
        "train_features = create_core_features(train)\n",
        "print(\"âœ… í•µì‹¬ í”¼ì²˜ ìƒì„± ì™„ë£Œ\")\n",
        "\n",
        "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
        "print(f\"\\nğŸ” ê²°ì¸¡ì¹˜ í˜„í™©:\")\n",
        "lag_cols = ['sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_ma_7', 'sales_ma_14', 'sales_max_7', 'sales_min_7']\n",
        "for col in lag_cols:\n",
        "    missing = train_features[col].isna().sum()\n",
        "    print(f\"   {col}: {missing:,}ê°œ ({missing/len(train_features)*100:.1f}%)\")\n",
        "\n",
        "# ê²°ì¸¡ì¹˜ 0ìœ¼ë¡œ ëŒ€ì²´\n",
        "train_features[lag_cols] = train_features[lag_cols].fillna(0)\n",
        "print(\"\\nâœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– ê°„ë‹¨í•˜ê³  ê°•ë ¥í•œ ëª¨ë¸ë“¤ ì¤€ë¹„...\n",
            "âœ… ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ\n",
            "ğŸ“Š ì‚¬ìš©í•  í”¼ì²˜: 10ê°œ\n",
            "   ['dayofweek', 'month', 'is_weekend', 'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_ma_7', 'sales_ma_14', 'sales_max_7', 'sales_min_7']\n"
          ]
        }
      ],
      "source": [
        "# ğŸš€ ì´ˆê°•ë ¥ ê°„ë‹¨ ëª¨ë¸ë“¤\n",
        "print(\"ğŸ¤– ê°„ë‹¨í•˜ê³  ê°•ë ¥í•œ ëª¨ë¸ë“¤ ì¤€ë¹„...\")\n",
        "\n",
        "# í”¼ì²˜ ëª©ë¡\n",
        "feature_cols = ['dayofweek', 'month', 'is_weekend'] + lag_cols\n",
        "\n",
        "# 1. í–¥ìƒëœ Random Forest\n",
        "rf_params = {\n",
        "    'n_estimators': 200,\n",
        "    'max_depth': 10,\n",
        "    'min_samples_split': 5,\n",
        "    'min_samples_leaf': 2,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "\n",
        "# 2. ìµœì í™”ëœ LightGBM\n",
        "lgb_params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 63,\n",
        "    'learning_rate': 0.1,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# 3. ê°•í™”ëœ CatBoost\n",
        "cb_params = {\n",
        "    'iterations': 300,\n",
        "    'learning_rate': 0.1,\n",
        "    'depth': 8,\n",
        "    'l2_leaf_reg': 3,\n",
        "    'loss_function': 'RMSE',\n",
        "    'random_seed': 42,\n",
        "    'verbose': False\n",
        "}\n",
        "\n",
        "print(\"âœ… ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ\")\n",
        "print(f\"ğŸ“Š ì‚¬ìš©í•  í”¼ì²˜: {len(feature_cols)}ê°œ\")\n",
        "print(f\"   {feature_cols}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š íƒ€ì„ ì‹œë¦¬ì¦ˆ ê²€ì¦ ì„¤ì •...\n",
            "ğŸ“ˆ í›ˆë ¨ ë°ì´í„°: 98,623ê°œ (2023-01-01 00:00:00 ~ 2024-05-25 00:00:00)\n",
            "ğŸ“‰ ê²€ì¦ ë°ì´í„°: 4,053ê°œ (2024-05-26 00:00:00 ~ 2024-06-15 00:00:00)\n",
            "\n",
            "ğŸ”¢ í”¼ì²˜ í†µê³„:\n",
            "   X_train: (98623, 10)\n",
            "   y_train: í‰ê·  10.79, í‘œì¤€í¸ì°¨ 42.49\n",
            "   X_val: (4053, 10)\n",
            "   y_val: í‰ê·  7.28, í‘œì¤€í¸ì°¨ 22.62\n"
          ]
        }
      ],
      "source": [
        "# ğŸ¯ íƒ€ì„ ì‹œë¦¬ì¦ˆ ë¶„í•  ê²€ì¦\n",
        "print(\"ğŸ“Š íƒ€ì„ ì‹œë¦¬ì¦ˆ ê²€ì¦ ì„¤ì •...\")\n",
        "\n",
        "# ì‹œê°„ ê¸°ì¤€ ë¶„í•  (ìµœê·¼ 21ì¼ì„ ê²€ì¦ìš©ìœ¼ë¡œ)\n",
        "split_date = train_features['ì˜ì—…ì¼ì'].max() - pd.Timedelta(days=21)\n",
        "train_data = train_features[train_features['ì˜ì—…ì¼ì'] <= split_date].copy()\n",
        "val_data = train_features[train_features['ì˜ì—…ì¼ì'] > split_date].copy()\n",
        "\n",
        "print(f\"ğŸ“ˆ í›ˆë ¨ ë°ì´í„°: {len(train_data):,}ê°œ ({train_data['ì˜ì—…ì¼ì'].min()} ~ {train_data['ì˜ì—…ì¼ì'].max()})\")\n",
        "print(f\"ğŸ“‰ ê²€ì¦ ë°ì´í„°: {len(val_data):,}ê°œ ({val_data['ì˜ì—…ì¼ì'].min()} ~ {val_data['ì˜ì—…ì¼ì'].max()})\")\n",
        "\n",
        "# X, y ë¶„ë¦¬\n",
        "X_train = train_data[feature_cols]\n",
        "y_train = train_data['ë§¤ì¶œìˆ˜ëŸ‰']\n",
        "X_val = val_data[feature_cols]\n",
        "y_val = val_data['ë§¤ì¶œìˆ˜ëŸ‰']\n",
        "\n",
        "print(f\"\\nğŸ”¢ í”¼ì²˜ í†µê³„:\")\n",
        "print(f\"   X_train: {X_train.shape}\")\n",
        "print(f\"   y_train: í‰ê·  {y_train.mean():.2f}, í‘œì¤€í¸ì°¨ {y_train.std():.2f}\")\n",
        "print(f\"   X_val: {X_val.shape}\")\n",
        "print(f\"   y_val: í‰ê·  {y_val.mean():.2f}, í‘œì¤€í¸ì°¨ {y_val.std():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš¡ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...\n",
            "\n",
            "1ï¸âƒ£ Random Forest í›ˆë ¨...\n",
            "   RMSE: 14.671, MAE: 5.208, ì˜ˆì¸¡í‰ê· : 7.527\n",
            "\n",
            "2ï¸âƒ£ LightGBM í›ˆë ¨...\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[77]\tvalid_0's rmse: 14.5611\n",
            "   RMSE: 14.535, MAE: 5.081, ì˜ˆì¸¡í‰ê· : 7.672\n",
            "\n",
            "3ï¸âƒ£ CatBoost í›ˆë ¨...\n",
            "   RMSE: 14.296, MAE: 5.150, ì˜ˆì¸¡í‰ê· : 7.643\n",
            "\n",
            "âœ… ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# ğŸƒâ€â™‚ï¸ ë¹ ë¥¸ ëª¨ë¸ í›ˆë ¨ ë° ê²€ì¦\n",
        "print(\"âš¡ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...\")\n",
        "\n",
        "models = {}\n",
        "val_scores = {}\n",
        "\n",
        "# 1. Random Forest\n",
        "print(\"\\n1ï¸âƒ£ Random Forest í›ˆë ¨...\")\n",
        "rf = RandomForestRegressor(**rf_params)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_val)\n",
        "rf_pred = np.maximum(rf_pred, 0)  # ìŒìˆ˜ ë°©ì§€\n",
        "\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_val, rf_pred))\n",
        "rf_mae = mean_absolute_error(y_val, rf_pred)\n",
        "models['RandomForest'] = rf\n",
        "val_scores['RandomForest'] = {'RMSE': rf_rmse, 'MAE': rf_mae, 'Mean': rf_pred.mean()}\n",
        "\n",
        "print(f\"   RMSE: {rf_rmse:.3f}, MAE: {rf_mae:.3f}, ì˜ˆì¸¡í‰ê· : {rf_pred.mean():.3f}\")\n",
        "\n",
        "# 2. LightGBM\n",
        "print(\"\\n2ï¸âƒ£ LightGBM í›ˆë ¨...\")\n",
        "train_lgb = lgb.Dataset(X_train, label=y_train)\n",
        "val_lgb = lgb.Dataset(X_val, label=y_val, reference=train_lgb)\n",
        "\n",
        "lgb_model = lgb.train(lgb_params, train_lgb, \n",
        "                      valid_sets=[val_lgb], num_boost_round=500,\n",
        "                      callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)])\n",
        "\n",
        "lgb_pred = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
        "lgb_pred = np.maximum(lgb_pred, 0)\n",
        "\n",
        "lgb_rmse = np.sqrt(mean_squared_error(y_val, lgb_pred))\n",
        "lgb_mae = mean_absolute_error(y_val, lgb_pred)\n",
        "models['LightGBM'] = lgb_model\n",
        "val_scores['LightGBM'] = {'RMSE': lgb_rmse, 'MAE': lgb_mae, 'Mean': lgb_pred.mean()}\n",
        "\n",
        "print(f\"   RMSE: {lgb_rmse:.3f}, MAE: {lgb_mae:.3f}, ì˜ˆì¸¡í‰ê· : {lgb_pred.mean():.3f}\")\n",
        "\n",
        "# 3. CatBoost\n",
        "print(\"\\n3ï¸âƒ£ CatBoost í›ˆë ¨...\")\n",
        "cb = CatBoostRegressor(**cb_params)\n",
        "cb.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=30)\n",
        "\n",
        "cb_pred = cb.predict(X_val)\n",
        "cb_pred = np.maximum(cb_pred, 0)\n",
        "\n",
        "cb_rmse = np.sqrt(mean_squared_error(y_val, cb_pred))\n",
        "cb_mae = mean_absolute_error(y_val, cb_pred)\n",
        "models['CatBoost'] = cb\n",
        "val_scores['CatBoost'] = {'RMSE': cb_rmse, 'MAE': cb_mae, 'Mean': cb_pred.mean()}\n",
        "\n",
        "print(f\"   RMSE: {cb_rmse:.3f}, MAE: {cb_mae:.3f}, ì˜ˆì¸¡í‰ê· : {cb_pred.mean():.3f}\")\n",
        "\n",
        "print(\"\\nâœ… ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ† ì„±ëŠ¥ ë¹„êµ (ë² ì´ìŠ¤ë¼ì¸ vs ìƒˆ ëª¨ë¸ë“¤)\n",
            "================================================================================\n",
            "ğŸ“‹ ë² ì´ìŠ¤ë¼ì¸ LSTM:\n",
            "   í‰ê· : 9.739 | í‘œì¤€í¸ì°¨: 36.115 | 0ë¹„ìœ¨: 0.126\n",
            "\n",
            "ğŸ“Š ìƒì„¸ ì„±ëŠ¥ ë¶„ì„:\n",
            "ëª¨ë¸ëª…        | RMSE   | MAE    | í‰ê·    | í‘œì¤€í¸ì°¨ | 0ë¹„ìœ¨  | ë¶„í¬ì°¨ì´ | ì¢…í•©ì ìˆ˜\n",
            "--------------------------------------------------------------------------------\n",
            "RandomForest |  14.67 |   5.21 |   7.53 |    17.50 |  0.099 |     0.00 |   -14.67\n",
            "LightGBM     |  14.54 |   5.08 |   7.67 |    18.70 |  0.003 |     0.00 |   -14.54\n",
            "CatBoost     |  14.30 |   5.15 |   7.64 |    17.79 |  0.084 |     0.00 |   -14.30\n",
            "--------------------------------------------------------------------------------\n",
            "ë² ì´ìŠ¤ë¼ì¸    |        |        |   9.74 |    36.11 |  0.126 |          |       ê¸°ì¤€\n",
            "\n",
            "================================================================================\n",
            "ğŸ¥‡ ë² ìŠ¤íŠ¸ ëª¨ë¸: CatBoost (ì¢…í•©ì ìˆ˜: -14.30)\n",
            "   âœ… RMSE, MAE, ë¶„í¬ ìœ ì‚¬ì„±ì„ ì¢…í•© ê³ ë ¤í•œ ì„ íƒ\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“Š ì„±ëŠ¥ ë¹„êµ ë° ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ\n",
        "print(\"ğŸ† ì„±ëŠ¥ ë¹„êµ (ë² ì´ìŠ¤ë¼ì¸ vs ìƒˆ ëª¨ë¸ë“¤)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ë² ì´ìŠ¤ë¼ì¸ í†µê³„\n",
        "baseline_mean = baseline_stats.mean()\n",
        "baseline_std = baseline_stats.std()\n",
        "baseline_zero_ratio = (baseline_stats == 0).mean()\n",
        "\n",
        "print(f\"ğŸ“‹ ë² ì´ìŠ¤ë¼ì¸ LSTM:\")\n",
        "print(f\"   í‰ê· : {baseline_mean:.3f} | í‘œì¤€í¸ì°¨: {baseline_std:.3f} | 0ë¹„ìœ¨: {baseline_zero_ratio:.3f}\")\n",
        "print()\n",
        "\n",
        "# ë” ì¢…í•©ì ì¸ í‰ê°€ë¥¼ ìœ„í•œ ìŠ¤ì½”ì–´ë§ í•¨ìˆ˜\n",
        "def calculate_comprehensive_score(pred_values, actual_values, model_name):\n",
        "    \"\"\"ì¢…í•©ì ì¸ ëª¨ë¸ í‰ê°€ ìŠ¤ì½”ì–´\"\"\"\n",
        "    rmse = np.sqrt(mean_squared_error(actual_values, pred_values))\n",
        "    mae = mean_absolute_error(actual_values, pred_values)\n",
        "    \n",
        "    # ì¶”ê°€ ì§€í‘œë“¤\n",
        "    pred_mean = pred_values.mean()\n",
        "    pred_std = pred_values.std()\n",
        "    zero_ratio = (pred_values == 0).mean()\n",
        "    \n",
        "    # ì‹¤ì œê°’ê³¼ì˜ ë¶„í¬ ìœ ì‚¬ì„± (Jensen-Shannon divergence ê·¼ì‚¬)\n",
        "    # ê°’ì˜ ë²”ìœ„ë¥¼ ë§ì¶°ì„œ íˆìŠ¤í† ê·¸ë¨ ë¹„êµ\n",
        "    try:\n",
        "        max_val = max(actual_values.max(), pred_values.max())\n",
        "        bins = np.linspace(0, max_val, 20)\n",
        "        hist_actual, _ = np.histogram(actual_values, bins=bins, density=True)\n",
        "        hist_pred, _ = np.histogram(pred_values, bins=bins, density=True)\n",
        "        \n",
        "        # KL divergence ê·¼ì‚¬ (0 ë°©ì§€ë¥¼ ìœ„í•´ ì‘ì€ ê°’ ì¶”ê°€)\n",
        "        hist_actual = hist_actual + 1e-10\n",
        "        hist_pred = hist_pred + 1e-10\n",
        "        kl_div = np.sum(hist_actual * np.log(hist_actual / hist_pred))\n",
        "    except:\n",
        "        kl_div = 999  # ê³„ì‚° ì‹¤íŒ¨ì‹œ í˜ë„í‹°\n",
        "    \n",
        "    return {\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae, \n",
        "        'Mean': pred_mean,\n",
        "        'Std': pred_std,\n",
        "        'ZeroRatio': zero_ratio,\n",
        "        'KL_Div': kl_div,\n",
        "        # ì¢…í•© ì ìˆ˜ (RMSEê°€ ë‚®ê³ , ë¶„í¬ê°€ ìœ ì‚¬í• ìˆ˜ë¡ ì¢‹ìŒ)\n",
        "        'ComprehensiveScore': -(rmse + kl_div * 0.1)  # ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ\n",
        "    }\n",
        "\n",
        "best_model = None\n",
        "best_score = -999\n",
        "best_name = \"\"\n",
        "\n",
        "print(\"ğŸ“Š ìƒì„¸ ì„±ëŠ¥ ë¶„ì„:\")\n",
        "print(\"ëª¨ë¸ëª…        | RMSE   | MAE    | í‰ê·    | í‘œì¤€í¸ì°¨ | 0ë¹„ìœ¨  | ë¶„í¬ì°¨ì´ | ì¢…í•©ì ìˆ˜\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for name, scores in val_scores.items():\n",
        "    # ì˜ˆì¸¡ê°’ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°\n",
        "    if name == 'RandomForest':\n",
        "        pred_vals = models[name].predict(X_val)\n",
        "        pred_vals = np.maximum(pred_vals, 0)\n",
        "    elif name == 'LightGBM':\n",
        "        pred_vals = models[name].predict(X_val, num_iteration=models[name].best_iteration)\n",
        "        pred_vals = np.maximum(pred_vals, 0)\n",
        "    elif name == 'CatBoost':\n",
        "        pred_vals = models[name].predict(X_val)\n",
        "        pred_vals = np.maximum(pred_vals, 0)\n",
        "    \n",
        "    # ì¢…í•© í‰ê°€\n",
        "    comp_scores = calculate_comprehensive_score(pred_vals, y_val.values, name)\n",
        "    \n",
        "    print(f\"{name:12} | {comp_scores['RMSE']:6.2f} | {comp_scores['MAE']:6.2f} | \"\n",
        "          f\"{comp_scores['Mean']:6.2f} | {comp_scores['Std']:8.2f} | \"\n",
        "          f\"{comp_scores['ZeroRatio']:6.3f} | {comp_scores['KL_Div']:8.2f} | \"\n",
        "          f\"{comp_scores['ComprehensiveScore']:8.2f}\")\n",
        "    \n",
        "    # ì¢…í•© ì ìˆ˜ë¡œ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ\n",
        "    if comp_scores['ComprehensiveScore'] > best_score:\n",
        "        best_score = comp_scores['ComprehensiveScore']\n",
        "        best_model = models[name]\n",
        "        best_name = name\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(f\"ë² ì´ìŠ¤ë¼ì¸    | {'':6} | {'':6} | {baseline_mean:6.2f} | {baseline_std:8.2f} | \"\n",
        "      f\"{baseline_zero_ratio:6.3f} | {'':8} | {'ê¸°ì¤€':>8}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"ğŸ¥‡ ë² ìŠ¤íŠ¸ ëª¨ë¸: {best_name} (ì¢…í•©ì ìˆ˜: {best_score:.2f})\")\n",
        "print(\"   âœ… RMSE, MAE, ë¶„í¬ ìœ ì‚¬ì„±ì„ ì¢…í•© ê³ ë ¤í•œ ì„ íƒ\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í›ˆë ¨...\n",
            "ğŸ“Š ì „ì²´ í›ˆë ¨ ë°ì´í„°: (102676, 10)\n",
            "ğŸ± CatBoost ìµœì¢… í›ˆë ¨...\n",
            "âœ… CatBoost ìµœì¢… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!\n",
            "\n",
            "ğŸ“ˆ CatBoost í”¼ì²˜ ì¤‘ìš”ë„:\n",
            "   sales_ma_7      : 25.740\n",
            "   dayofweek       : 14.319\n",
            "   sales_max_7     : 12.217\n",
            "   sales_lag_1     : 9.864\n",
            "   sales_lag_7     : 8.270\n"
          ]
        }
      ],
      "source": [
        "# ğŸš€ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ ì¬í›ˆë ¨\n",
        "print(\"ğŸ”„ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í›ˆë ¨...\")\n",
        "\n",
        "# ì „ì²´ í›ˆë ¨ ë°ì´í„° ì¤€ë¹„\n",
        "X_full = train_features[feature_cols]\n",
        "y_full = train_features['ë§¤ì¶œìˆ˜ëŸ‰']\n",
        "\n",
        "print(f\"ğŸ“Š ì „ì²´ í›ˆë ¨ ë°ì´í„°: {X_full.shape}\")\n",
        "\n",
        "# ë² ìŠ¤íŠ¸ ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ì¬í›ˆë ¨\n",
        "if best_name == 'RandomForest':\n",
        "    print(\"ğŸŒ² Random Forest ìµœì¢… í›ˆë ¨...\")\n",
        "    final_model = RandomForestRegressor(**rf_params)\n",
        "    final_model.fit(X_full, y_full)\n",
        "    \n",
        "elif best_name == 'LightGBM':\n",
        "    print(\"ğŸ’¡ LightGBM ìµœì¢… í›ˆë ¨...\")\n",
        "    full_lgb = lgb.Dataset(X_full, label=y_full)\n",
        "    final_model = lgb.train(lgb_params, full_lgb, num_boost_round=500, callbacks=[lgb.log_evaluation(0)])\n",
        "    \n",
        "elif best_name == 'CatBoost':\n",
        "    print(\"ğŸ± CatBoost ìµœì¢… í›ˆë ¨...\")\n",
        "    final_model = CatBoostRegressor(**cb_params)\n",
        "    final_model.fit(X_full, y_full)\n",
        "\n",
        "print(f\"âœ… {best_name} ìµœì¢… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!\")\n",
        "\n",
        "# ëª¨ë¸ë³„ ì¤‘ìš” í”¼ì²˜ í™•ì¸ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
        "if hasattr(final_model, 'feature_importances_'):\n",
        "    feature_importance = final_model.feature_importances_\n",
        "    feature_df = pd.DataFrame({\n",
        "        'feature': feature_cols,\n",
        "        'importance': feature_importance\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(f\"\\nğŸ“ˆ {best_name} í”¼ì²˜ ì¤‘ìš”ë„:\")\n",
        "    for _, row in feature_df.head(5).iterrows():\n",
        "        print(f\"   {row['feature']:15} : {row['importance']:.3f}\")\n",
        "elif hasattr(final_model, 'get_feature_importance'):\n",
        "    feature_importance = final_model.get_feature_importance()\n",
        "    feature_df = pd.DataFrame({\n",
        "        'feature': feature_cols,\n",
        "        'importance': feature_importance\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(f\"\\nğŸ“ˆ {best_name} í”¼ì²˜ ì¤‘ìš”ë„:\")\n",
        "    for _, row in feature_df.head(5).iterrows():\n",
        "        print(f\"   {row['feature']:15} : {row['importance']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘...\n",
            "ğŸ“Š ì˜ˆì¸¡ ëŒ€ìƒ: 193ê°œ ì—…ì¥-ë©”ë‰´\n",
            "   ì§„í–‰ë¥ : 0/193 (0.0%)\n",
            "   ì§„í–‰ë¥ : 50/193 (25.9%)\n",
            "   ì§„í–‰ë¥ : 100/193 (51.8%)\n",
            "   ì§„í–‰ë¥ : 150/193 (77.7%)\n",
            "âœ… ëª¨ë“  ì—…ì¥-ë©”ë‰´ ì˜ˆì¸¡ ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
        "print(\"ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘...\")\n",
        "\n",
        "def predict_for_venue_menu(venue_menu, model, model_name):\n",
        "    \"\"\"ì—…ì¥-ë©”ë‰´ë³„ 7ì¼ ì˜ˆì¸¡\"\"\"\n",
        "    # í•´ë‹¹ ì—…ì¥-ë©”ë‰´ì˜ ìµœê·¼ ë°ì´í„°\n",
        "    venue_data = train_features[train_features['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == venue_menu].copy()\n",
        "    \n",
        "    if len(venue_data) == 0:\n",
        "        return np.zeros(7)\n",
        "    \n",
        "    venue_data = venue_data.sort_values('ì˜ì—…ì¼ì').tail(28)  # ìµœê·¼ 28ì¼\n",
        "    \n",
        "    # ë¯¸ë˜ 7ì¼ ì˜ˆì¸¡\n",
        "    predictions = []\n",
        "    \n",
        "    # ê¸°ì¤€ì¼ (2024-06-16ë¶€í„° 7ì¼)\n",
        "    last_date = venue_data['ì˜ì—…ì¼ì'].max()\n",
        "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=7)\n",
        "    \n",
        "    for i, future_date in enumerate(future_dates):\n",
        "        # ë¯¸ë˜ ë‚ ì§œì˜ ì‹œê°„ í”¼ì²˜\n",
        "        future_dayofweek = future_date.dayofweek\n",
        "        future_month = future_date.month\n",
        "        future_is_weekend = future_dayofweek in [5, 6]\n",
        "        \n",
        "        # ìµœê·¼ ë°ì´í„°ì—ì„œ ë¼ê·¸ í”¼ì²˜ ê³„ì‚°\n",
        "        if len(venue_data) >= 1:\n",
        "            sales_lag_1 = venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].iloc[-1] if len(venue_data) >= 1 else 0\n",
        "        else:\n",
        "            sales_lag_1 = 0\n",
        "            \n",
        "        if len(venue_data) >= 7:\n",
        "            sales_lag_7 = venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].iloc[-7] if len(venue_data) >= 7 else 0\n",
        "        else:\n",
        "            sales_lag_7 = 0\n",
        "            \n",
        "        if len(venue_data) >= 14:\n",
        "            sales_lag_14 = venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].iloc[-14] if len(venue_data) >= 14 else 0\n",
        "        else:\n",
        "            sales_lag_14 = 0\n",
        "        \n",
        "        # ì´ë™í‰ê·  ê³„ì‚°\n",
        "        sales_ma_7 = venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].tail(7).mean() if len(venue_data) >= 7 else venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].mean()\n",
        "        sales_ma_14 = venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].tail(14).mean() if len(venue_data) >= 14 else venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].mean()\n",
        "        \n",
        "        # ìµœëŒ€/ìµœì†Œ\n",
        "        sales_max_7 = venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].tail(7).max() if len(venue_data) >= 7 else venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].max()\n",
        "        sales_min_7 = venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].tail(7).min() if len(venue_data) >= 7 else venue_data['ë§¤ì¶œìˆ˜ëŸ‰'].min()\n",
        "        \n",
        "        # í”¼ì²˜ ë²¡í„° ìƒì„±\n",
        "        features = np.array([[\n",
        "            future_dayofweek, future_month, future_is_weekend,\n",
        "            sales_lag_1, sales_lag_7, sales_lag_14,\n",
        "            sales_ma_7, sales_ma_14, sales_max_7, sales_min_7\n",
        "        ]])\n",
        "        \n",
        "        # ì˜ˆì¸¡\n",
        "        if model_name == 'LightGBM':\n",
        "            pred = model.predict(features)[0]\n",
        "        else:\n",
        "            pred = model.predict(features)[0]\n",
        "        \n",
        "        pred = max(0, pred)  # ìŒìˆ˜ ë°©ì§€\n",
        "        predictions.append(pred)\n",
        "        \n",
        "        # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ í˜„ì¬ ì˜ˆì¸¡ê°’ì„ ê°€ìƒìœ¼ë¡œ ì¶”ê°€ (ê°„ë‹¨í•œ ìˆœì°¨ ì˜ˆì¸¡)\n",
        "        new_row = venue_data.iloc[-1].copy()\n",
        "        new_row['ì˜ì—…ì¼ì'] = future_date\n",
        "        new_row['ë§¤ì¶œìˆ˜ëŸ‰'] = pred\n",
        "        new_row['dayofweek'] = future_dayofweek\n",
        "        new_row['month'] = future_month\n",
        "        new_row['is_weekend'] = future_is_weekend\n",
        "        \n",
        "        venue_data = pd.concat([venue_data, new_row.to_frame().T], ignore_index=True)\n",
        "    \n",
        "    return np.array(predictions)\n",
        "\n",
        "# ëª¨ë“  ì—…ì¥-ë©”ë‰´ì— ëŒ€í•´ ì˜ˆì¸¡\n",
        "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
        "venue_menus = [col for col in sample_submission.columns if col != 'ì˜ì—…ì¼ì']\n",
        "\n",
        "print(f\"ğŸ“Š ì˜ˆì¸¡ ëŒ€ìƒ: {len(venue_menus)}ê°œ ì—…ì¥-ë©”ë‰´\")\n",
        "\n",
        "all_predictions = {}\n",
        "for i, venue_menu in enumerate(venue_menus):\n",
        "    if i % 50 == 0:\n",
        "        print(f\"   ì§„í–‰ë¥ : {i}/{len(venue_menus)} ({i/len(venue_menus)*100:.1f}%)\")\n",
        "    \n",
        "    predictions = predict_for_venue_menu(venue_menu, final_model, best_name)\n",
        "    all_predictions[venue_menu] = predictions\n",
        "\n",
        "print(\"âœ… ëª¨ë“  ì—…ì¥-ë©”ë‰´ ì˜ˆì¸¡ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‹ ì œì¶œ íŒŒì¼ ìƒì„±...\n",
            "âœ… ì œì¶œ íŒŒì¼ ì €ì¥: ../submission_emergency_CatBoost_20250824_171129.csv\n",
            "\n",
            "ğŸ“Š ìµœì¢… ì œì¶œ íŒŒì¼ í†µê³„:\n",
            "   ëª¨ë¸: CatBoost\n",
            "   í‰ê· : 6.766\n",
            "   í‘œì¤€í¸ì°¨: 16.893\n",
            "   ìµœëŒ€ê°’: 169.700\n",
            "   0ì´ ì•„ë‹Œ ë¹„ìœ¨: 0.869\n",
            "\n",
            "ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ vs ìµœì¢… ëª¨ë¸ ì¢…í•© ë¹„êµ:\n",
            "============================================================\n",
            "ì§€í‘œ            | ë² ì´ìŠ¤ë¼ì¸   | CatBoost     | ì°¨ì´\n",
            "------------------------------------------------------------\n",
            "í‰ê·             |      9.739 |      6.766 |  -2.973 ğŸ˜…\n",
            "í‘œì¤€í¸ì°¨        |     36.115 |     16.893 | -19.222 âš ï¸\n",
            "0 ë¹„ìœ¨          |      0.126 |      0.131 |  +0.005 âš ï¸\n",
            "ìµœëŒ€ê°’          |     1057.8 |      169.7 |  -888.1 âš ï¸\n",
            "------------------------------------------------------------\n",
            "ğŸ˜… ì¢…í•© í‰ê°€: ì•„ì‰½ì§€ë§Œ ìµœì„ ì„ ë‹¤í•¨ (0/4 ì§€í‘œ ê°œì„ )\n",
            "============================================================\n",
            "ğŸ’¡ í•µì‹¬: ë‹¨ìˆœí•œ í‰ê· ê°’ ë¹„êµë³´ë‹¤ ë¶„í¬, ë³€ë™ì„±, ê·¹ê°’ì„ ì¢…í•© ê³ ë ¤!\n"
          ]
        }
      ],
      "source": [
        "# ğŸ’¾ ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "print(\"ğŸ“‹ ì œì¶œ íŒŒì¼ ìƒì„±...\")\n",
        "\n",
        "# ì œì¶œ íŒŒì¼ í˜•ì‹ ë§ì¶”ê¸°\n",
        "submission = pd.read_csv('../data/sample_submission.csv')\n",
        "\n",
        "# ëª¨ë“  ê°’ì„ floatìœ¼ë¡œ ë³€í™˜\n",
        "for col in submission.columns:\n",
        "    if col != 'ì˜ì—…ì¼ì':\n",
        "        submission[col] = submission[col].astype(float)\n",
        "\n",
        "# ì˜ˆì¸¡ê°’ í• ë‹¹\n",
        "for venue_menu in venue_menus:\n",
        "    if venue_menu in all_predictions:\n",
        "        predictions = all_predictions[venue_menu]  # 7ì¼ ì˜ˆì¸¡\n",
        "        \n",
        "        # ëª¨ë“  70ê°œ ë‚ ì§œì— ëŒ€í•´ 7ì¼ íŒ¨í„´ ë°˜ë³µ\n",
        "        for row_idx in range(len(submission)):\n",
        "            date_name = submission.loc[row_idx, 'ì˜ì—…ì¼ì']\n",
        "            \n",
        "            # +Xì¼ì—ì„œ X ì¶”ì¶œ\n",
        "            if '+' in date_name and 'ì¼' in date_name:\n",
        "                day_part = date_name.split('+')[1].replace('ì¼', '')\n",
        "                try:\n",
        "                    day_number = int(day_part)  # 1~7\n",
        "                    pred_idx = (day_number - 1) % 7\n",
        "                    \n",
        "                    if pred_idx < len(predictions):\n",
        "                        pred_value = max(0.0, round(float(predictions[pred_idx]), 1))\n",
        "                        submission.loc[row_idx, venue_menu] = pred_value\n",
        "                except ValueError:\n",
        "                    pass\n",
        "\n",
        "# íŒŒì¼ ì €ì¥\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "filename = f'../submission_emergency_{best_name}_{timestamp}.csv'\n",
        "submission.to_csv(filename, index=False)\n",
        "\n",
        "print(f\"âœ… ì œì¶œ íŒŒì¼ ì €ì¥: {filename}\")\n",
        "\n",
        "# ìµœì¢… í†µê³„\n",
        "final_stats = submission.iloc[:, 1:].values\n",
        "print(f\"\\nğŸ“Š ìµœì¢… ì œì¶œ íŒŒì¼ í†µê³„:\")\n",
        "print(f\"   ëª¨ë¸: {best_name}\")\n",
        "print(f\"   í‰ê· : {final_stats.mean():.3f}\")\n",
        "print(f\"   í‘œì¤€í¸ì°¨: {final_stats.std():.3f}\")\n",
        "print(f\"   ìµœëŒ€ê°’: {final_stats.max():.3f}\")\n",
        "print(f\"   0ì´ ì•„ë‹Œ ë¹„ìœ¨: {(final_stats > 0).mean():.3f}\")\n",
        "\n",
        "# ë² ì´ìŠ¤ë¼ì¸ê³¼ ì¢…í•©ì  ë¹„êµ\n",
        "print(f\"\\nğŸ“Š ë² ì´ìŠ¤ë¼ì¸ vs ìµœì¢… ëª¨ë¸ ì¢…í•© ë¹„êµ:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"ì§€í‘œ            | ë² ì´ìŠ¤ë¼ì¸   | {best_name:12} | ì°¨ì´\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "# í‰ê·  ë¹„êµ\n",
        "mean_diff = final_stats.mean() - baseline_mean\n",
        "mean_symbol = \"ğŸš€\" if mean_diff > 0 else \"ğŸ˜…\"\n",
        "print(f\"í‰ê·             | {baseline_mean:10.3f} | {final_stats.mean():10.3f} | {mean_diff:+7.3f} {mean_symbol}\")\n",
        "\n",
        "# í‘œì¤€í¸ì°¨ ë¹„êµ (ë³€ë™ì„±)\n",
        "std_diff = final_stats.std() - baseline_std\n",
        "std_symbol = \"ğŸ“ˆ\" if abs(std_diff) < 0.5 else \"âš ï¸\"  # ë¹„ìŠ·í•œ ë³€ë™ì„±ì´ ì¢‹ìŒ\n",
        "print(f\"í‘œì¤€í¸ì°¨        | {baseline_std:10.3f} | {final_stats.std():10.3f} | {std_diff:+7.3f} {std_symbol}\")\n",
        "\n",
        "# 0 ë¹„ìœ¨ ë¹„êµ\n",
        "zero_ratio_final = (final_stats == 0).mean()\n",
        "zero_diff = zero_ratio_final - baseline_zero_ratio  \n",
        "zero_symbol = \"âœ…\" if zero_diff < 0 else \"âš ï¸\"  # 0ì´ ì ì„ìˆ˜ë¡ ì¢‹ìŒ\n",
        "print(f\"0 ë¹„ìœ¨          | {baseline_zero_ratio:10.3f} | {zero_ratio_final:10.3f} | {zero_diff:+7.3f} {zero_symbol}\")\n",
        "\n",
        "# ìµœëŒ€ê°’ ë¹„êµ\n",
        "max_diff = final_stats.max() - baseline_stats.max()\n",
        "max_symbol = \"ğŸ“Š\" if abs(max_diff) < baseline_stats.max() * 0.3 else \"âš ï¸\"\n",
        "print(f\"ìµœëŒ€ê°’          | {baseline_stats.max():10.1f} | {final_stats.max():10.1f} | {max_diff:+7.1f} {max_symbol}\")\n",
        "\n",
        "print(\"-\"*60)\n",
        "\n",
        "# ì¢…í•© í‰ê°€\n",
        "positive_indicators = 0\n",
        "total_indicators = 4\n",
        "\n",
        "if mean_diff > 0: positive_indicators += 1\n",
        "if abs(std_diff) < 0.5: positive_indicators += 1  \n",
        "if zero_diff < 0: positive_indicators += 1\n",
        "if abs(max_diff) < baseline_stats.max() * 0.3: positive_indicators += 1\n",
        "\n",
        "success_rate = positive_indicators / total_indicators\n",
        "\n",
        "if success_rate >= 0.75:\n",
        "    print(f\"ğŸ‰ ì¢…í•© í‰ê°€: ë§¤ìš° ì„±ê³µì ! ({positive_indicators}/{total_indicators} ì§€í‘œ ê°œì„ )\")\n",
        "elif success_rate >= 0.5:\n",
        "    print(f\"âœ… ì¢…í•© í‰ê°€: ê´œì°®ì€ ì„±ê³¼ ({positive_indicators}/{total_indicators} ì§€í‘œ ê°œì„ )\")\n",
        "else:\n",
        "    print(f\"ğŸ˜… ì¢…í•© í‰ê°€: ì•„ì‰½ì§€ë§Œ ìµœì„ ì„ ë‹¤í•¨ ({positive_indicators}/{total_indicators} ì§€í‘œ ê°œì„ )\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"ğŸ’¡ í•µì‹¬: ë‹¨ìˆœí•œ í‰ê· ê°’ ë¹„êµë³´ë‹¤ ë¶„í¬, ë³€ë™ì„±, ê·¹ê°’ì„ ì¢…í•© ê³ ë ¤!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ ê¸´ê¸‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\n",
        "\n",
        "## ğŸ¯ ì „ëµ ìš”ì•½\n",
        "1. **ë‹¨ìˆœí•¨ì´ ë‹µ**: ë³µì¡í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ëŒ€ì‹  í•µì‹¬ ë¼ê·¸ í”¼ì²˜ì— ì§‘ì¤‘\n",
        "2. **íš¨ê³¼ì ì¸ ëª¨ë¸**: Random Forest, LightGBM, CatBoost 3ì¢… ë¹„êµ\n",
        "3. **ì‹¤ìš©ì  ê²€ì¦**: íƒ€ì„ ì‹œë¦¬ì¦ˆ ë¶„í• ë¡œ ì‹¤ì œ ì„±ëŠ¥ í™•ì¸\n",
        "4. **ë¹ ë¥¸ ì‹¤í–‰**: ë³µì¡í•œ ì•™ìƒë¸” ì—†ì´ ë² ìŠ¤íŠ¸ ëª¨ë¸ ë‹¨ì¼ ì‚¬ìš©\n",
        "\n",
        "## ğŸš€ í•µì‹¬ ê°œì„ ì \n",
        "- ë§¤ì¶œìˆ˜ëŸ‰ ì¤‘ì‹¬ì˜ ê°„ê²°í•œ í”¼ì²˜ë§\n",
        "- lag_1, lag_7, lag_14 + ì´ë™í‰ê·  + ìµœëŒ€/ìµœì†Œ\n",
        "- ì‹œê°„ í”¼ì²˜ëŠ” ìµœì†Œí•œ (dayofweek, month, is_weekend)\n",
        "- ìˆœì°¨ ì˜ˆì¸¡ìœ¼ë¡œ ë¯¸ë˜ 7ì¼ ì—°ì† ì˜ˆì¸¡\n",
        "\n",
        "## ğŸ“Š ê°œì„ ëœ í‰ê°€ ì§€í‘œ ì„¤ëª…\n",
        "**ì™œ í‰ê· ê°’ë§Œìœ¼ë¡  ë¶€ì¡±í•œê°€?**\n",
        "1. **RMSE & MAE**: ì‹¤ì œ ì˜ˆì¸¡ ì •í™•ë„ ì¸¡ì • (í•µì‹¬ ì§€í‘œ)\n",
        "2. **í‘œì¤€í¸ì°¨**: ì˜ˆì¸¡ ë³€ë™ì„± - ë„ˆë¬´ ë†’ê±°ë‚˜ ë‚®ìœ¼ë©´ ë¶€ìì—°ìŠ¤ëŸ¬ì›€\n",
        "3. **0 ë¹„ìœ¨**: ë§¤ì¶œì´ ì—†ëŠ” ë‚ ì˜ ë¹„ìœ¨ - í˜„ì‹¤ì„± ë°˜ì˜\n",
        "4. **ë¶„í¬ ìœ ì‚¬ì„±**: KL divergenceë¡œ ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì˜ ë¶„í¬ ë¹„êµ\n",
        "5. **ìµœëŒ€ê°’**: ê·¹ê°’ì˜ í˜„ì‹¤ì„± - ë„ˆë¬´ í¬ë©´ over-prediction\n",
        "\n",
        "**ì¢…í•© ì ìˆ˜**: RMSE(ì˜ˆì¸¡ ì •í™•ë„) + ë¶„í¬ ìœ ì‚¬ì„±ì„ ê²°í•©í•œ ê· í˜•ì¡íŒ í‰ê°€\n",
        "\n",
        "## ğŸ“ˆ ë‹¤ìŒ ê°œì„  ë°©í–¥ (ì‹œê°„ì´ ë” ìˆë‹¤ë©´)\n",
        "1. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (GridSearch/Optuna)\n",
        "2. ì—…ì¥ë³„ ê°œë³„ ëª¨ë¸ë§  \n",
        "3. ê³„ì ˆì„± íŠ¹ì„± ê°•í™”\n",
        "4. Cross-validationìœ¼ë¡œ ë” robustí•œ ê²€ì¦\n",
        "5. ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±(uncertainty) ì •ëŸ‰í™”\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py310-aimers",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
